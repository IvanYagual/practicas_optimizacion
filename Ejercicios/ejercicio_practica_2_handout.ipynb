{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Ejercicio Práctica 2: optimización para el problema de regresión lineal"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["En la carpeta **data** encontrarás el fichero **data_linear_regression.npy** el cual contiene (en formato fichero de numpy) la matriz de datos que usaremos en este ejercicio.\n","\n","Carga dicho fichero y asígnale el nombre **data**. Recuerda, esto se hace en el módulo **numpy** en la forma \n","\n","data = np.load(ruta/nombre del fichero)\n","\n","A continuación, imprime por pantalla dicha matriz y su forma\n"]},{"cell_type":"code","execution_count":201,"metadata":{},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":202,"metadata":{},"outputs":[{"data":{"text/plain":["array([[ 4.22137467e-02,  5.82815214e-01,  2.12300528e+01],\n","       [-1.72428208e-01, -8.77858418e-01, -3.97660505e+01],\n","       [-5.28171752e-01, -1.07296862e+00, -7.02963331e+01],\n","       [ 3.19039096e-01, -2.49370375e-01,  1.41809817e+01],\n","       [ 8.65407629e-01, -2.30153870e+00, -1.25613989e+01],\n","       [ 1.13376944e+00, -1.09989127e+00,  4.38456953e+01],\n","       [ 1.62434536e+00, -6.11756414e-01,  9.32631853e+01],\n","       [-3.22417204e-01, -3.84054355e-01, -3.44784013e+01],\n","       [ 1.74481176e+00, -7.61206901e-01,  9.65655196e+01],\n","       [ 1.46210794e+00, -2.06014071e+00,  3.59720885e+01]])"]},"execution_count":202,"metadata":{},"output_type":"execute_result"}],"source":["# Completar aquí\n","data = np.load(\"/home/ivan/practicas_optimizacion/Data/data_linear_regression.npy\")\n","data\n","# --------------------\n"]},{"cell_type":"code","execution_count":203,"metadata":{},"outputs":[{"data":{"text/plain":["(10, 3)"]},"execution_count":203,"metadata":{},"output_type":"execute_result"}],"source":["data.shape"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Como puedes observar, **data** es una matriz de $10$ filas y $3$ columnas.\n","\n","Las dos primeras columnas son de **features** y la última es de **labels**. Cada fila es una **instance** (muestra)\n","\n","Vamos a utilizar las $8$ primeras filas para entrenar nuestro modelo de regresión lineal y las dos últimas filas para testear la bondad del modelo. Por tanto, usando la técnica de **slicing** que estudiaste en Álgebra Lineal, construye una matriz **X_train** que contenga las $8$ primeras filas y las $2$ primeras columnas de **data** y luego una matriz **y_train** que contenga los datos de las $8$ primeras filas y última columna de **data**.\n","\n","De igual modo, construye **X_test** e **y_test** con los datos restantes. Imprime todo por pantalla para asegurarte que has seleccionado bien los datos."]},{"cell_type":"code","execution_count":204,"metadata":{},"outputs":[],"source":["# Completar aquí\n","X_train = data[:8, :2]\n","y_train = data[:8, 2:]\n","# --------------------\n"]},{"cell_type":"code","execution_count":205,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train:\n"," [[ 0.04221375  0.58281521]\n"," [-0.17242821 -0.87785842]\n"," [-0.52817175 -1.07296862]\n"," [ 0.3190391  -0.24937038]\n"," [ 0.86540763 -2.3015387 ]\n"," [ 1.13376944 -1.09989127]\n"," [ 1.62434536 -0.61175641]\n"," [-0.3224172  -0.38405435]]\n","\n","y_train:\n"," [[ 21.23005281]\n"," [-39.76605048]\n"," [-70.29633308]\n"," [ 14.18098172]\n"," [-12.56139894]\n"," [ 43.84569533]\n"," [ 93.26318528]\n"," [-34.47840128]]\n"]}],"source":["print(\"X_train:\\n\", X_train)\n","print(\"\\ny_train:\\n\", y_train)"]},{"cell_type":"code","execution_count":206,"metadata":{},"outputs":[],"source":["X_test = data[8:, :2]\n","y_test = data[8:, 2:]\n"]},{"cell_type":"code","execution_count":207,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X_test:\n"," [[ 1.74481176 -0.7612069 ]\n"," [ 1.46210794 -2.06014071]]\n","\n","y_test:\n"," [[96.56551964]\n"," [35.9720885 ]]\n"]}],"source":["print(\"X_test:\\n\", X_test)\n","print(\"\\ny_test:\\n\", y_test)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Resuelve de forma directa el problema de regresión lineal\n","\n","$$\n","\\text{Minimizar en } \\theta : \\quad \tMSE (\\theta) = \\frac{1}{8}\\sum_{i=1}^{8}\\left(\\theta^T x^{(i)} - y^{(i)}\\right)^2.\n","$$\n","\n","donde $x^{(i)}$ es la fila i-ésima de $X$ e $y^{(i)}$ la componente i-ésima del vector de labels.\n","\n","Recuerda añadir la columna de unos para el bias.\n"]},{"cell_type":"code","execution_count":208,"metadata":{},"outputs":[],"source":["# X_b: X_train con una columna de 1s para incluir el bias en la regresión lineal\n","X_b = np.c_[np.ones((X_train.shape[0], 1)), X_train]"]},{"cell_type":"code","execution_count":209,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["theta_best= \n","[[-5.10622756e-02]\n"," [ 6.92758412e+01]\n"," [ 3.14819495e+01]]\n"]}],"source":["# Completar aquí\n","theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y_train)\n","print(f\"theta_best= \\n{theta_best}\")\n","#SALIDA\n","#theta_best[0]: bias\n","#theta_best[1]: Coeficiente de x_1\n","#theta_best[2]: Coeficiente de x_2\n","# --------------------\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Resuelve el mismo problema con el método [scipy.linalg.lstsq](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.lstsq.html)"]},{"cell_type":"code","execution_count":210,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["theta_best= \n","[[-5.10622756e-02]\n"," [ 6.92758412e+01]\n"," [ 3.14819495e+01]]\n"]}],"source":["# Completar aquí\n","theta_best, residuals, rankm, s = np.linalg.lstsq(X_b.T.dot(X_b), X_b.T.dot(y_train), rcond=None)\n","print(f\"theta_best= \\n{theta_best}\")\n","# --------------------\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Define una función que nos de como salida el modelo de predicción de regresión lineal para el $\\theta_{\\text{best}}$ que has calculado previamente."]},{"cell_type":"code","execution_count":211,"metadata":{},"outputs":[],"source":["# Completar aquí\n","def model_predict(x, theta_best):\n","    predict = theta_best[0] + theta_best[1] * x[0] + theta_best[2] * x[1] \n","    return predict\n","# --------------------\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Evalua el modelo de predicción en los dos datos X_test y llama $y_1$, $y_2$ a los resultados obtenidos. Finalmente, compara los resultados con los datos y_test imprimiendo por pantalla:\n","\n","a) y_1\n","\n","b) y_test[0]\n","\n","c) y_2\n","\n","d) y_test[1]\n","\n","e) error de generalización = $\\frac{1}{2}\\left[\\left( y_1-y_{\\text{test}}[0]\\right)^2 + \\left( y_2-y_{\\text{test}}[1]\\right)^2\\right]$\n","\n"]},{"cell_type":"code","execution_count":212,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["y_1 = [96.8579633]\n","y_test[0] = [96.56551964]\n","y_2 = [36.38044931]\n","y_test[1] = [35.9720885]\n","Error de generalización = [0.12614092]\n"]}],"source":["# Completar aquí\n","y_1 = model_predict(X_test[0], theta_best)\n","print(\"y_1 =\", y_1)\n","print(\"y_test[0] =\", y_test[0])\n","\n","\n","y_2 = model_predict(X_test[1], theta_best)\n","print(\"y_2 =\", y_2)\n","print(\"y_test[1] =\", y_test[1])\n","\n","error = 1/2 * ((y_1 - y_test[0])**2 + (y_2 - y_test[1])**2) \n","\n","print(\"Error de generalización =\", error)\n","# --------------------\n"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"5b7942d5250582435657b631091e80c90197a20165d810d5d60089372acdfcb0"}}},"nbformat":4,"nbformat_minor":2}
